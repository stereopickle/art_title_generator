{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model2\n",
    "This notebook is a deeper iteration of similar architecture from model 1 set up for the purpose of running on AWS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "import tensorflow as tf\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'sagemaker-200928-21h35m'\n",
    "pkl_dir = f's3://{bucket}/PKL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copying file\n",
    "\n",
    "desc_path        = os.path.join(pkl_dir, 'condensed_descriptions.pkl')\n",
    "feat_path        = os.path.join(pkl_dir, 'full_features.pkl')\n",
    "train_list_path  = os.path.join(pkl_dir, 'train_list_full.pkl')\n",
    "val_list_path    = os.path.join(pkl_dir, 'val_list_full.pkl')\n",
    "test_list_path   = os.path.join(pkl_dir, 'test_list.pkl')\n",
    "test_art_path    = os.path.join(pkl_dir, 'test_list_art.pkl')\n",
    "\n",
    "!aws --region {region} s3 cp {desc_path}\n",
    "!aws --region {region} s3 cp {feat_path}\n",
    "!aws --region {region} s3 cp {train_list_path}\n",
    "!aws --region {region} s3 cp {val_list_path}\n",
    "!aws --region {region} s3 cp {test_list_path}\n",
    "!aws --region {region} s3 cp {test_art_path}\n",
    "\n",
    "descriptions = pickle.load('condensed_descriptions.pkl')\n",
    "features = pickle.load('full_features.pkl')\n",
    "train_list_full = pickle.load('train_list_full.pkl')\n",
    "val_list_full = pickle.load('val_list_full.pkl')\n",
    "test_list = pickle.load('test_list.pkl')\n",
    "test_list_art = pickle.load('test_list_art.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SCRIPT.sequence_generator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = sequence_generator(descriptions, features)\n",
    "\n",
    "train_X1, train_X2, train_Y = processor.train_generator(train_list_full)\n",
    "val_X1, val_X2, val_Y = processor.validation_generator(val_list_full)\n",
    "\n",
    "# get params\n",
    "tokenizer = processor.get_tokenizer()\n",
    "max_length = processor.get_max_length()\n",
    "num_vocab = processor.get_num_vocab()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_estimator = TensorFlow(entry_point = 'SCRIPT/nlg_model_tf_1.py', \n",
    "                         role = role, \n",
    "                         train_instance_count = 1, \n",
    "                         train_instance_type = 'local', \n",
    "                         py_version = 'py37', \n",
    "                         framework_version = '1.15.2',\n",
    "                         script_mode = True, \n",
    "                         hyperparameters = {'epochs': epochs, \n",
    "                                           'batch-size': batch_size}\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tmp9e2lguv4_algo-1-nfqu5_1 ... \n",
      "\u001b[1BAttaching to tmp9e2lguv4_algo-1-nfqu5_12mdone\u001b[0m\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m \n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m 2020-09-29 02:39:27,697 sagemaker-training-toolkit INFO     Imported framework sagemaker_tensorflow_container.training\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m 2020-09-29 02:39:27,703 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m 2020-09-29 02:39:28,877 sagemaker-training-toolkit INFO     Module nlg_model_tf_1.py does not provide a setup.py. \n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m Generating setup.py\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m 2020-09-29 02:39:28,878 sagemaker-training-toolkit INFO     Generating setup.cfg\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m 2020-09-29 02:39:28,878 sagemaker-training-toolkit INFO     Generating MANIFEST.in\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m 2020-09-29 02:39:28,878 sagemaker-training-toolkit INFO     Installing module with the following command:\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m /usr/local/bin/python3.7 -m pip install . \n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m Building wheels for collected packages: nlg-model-tf-1.py\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m   Building wheel for nlg-model-tf-1.py (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m \u001b[?25h  Created wheel for nlg-model-tf-1.py: filename=nlg_model_tf_1.py-1.0.0-py2.py3-none-any.whl size=7849 sha256=377c303e9c7d212241da70272e2df059b3adced56e6eaff2772ec50037104913\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m   Stored in directory: /tmp/pip-ephem-wheel-cache-735bpuns/wheels/3e/0f/51/2f1df833dd0412c1bc2f5ee56baac195b5be563353d111dca6\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m Successfully built nlg-model-tf-1.py\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m Installing collected packages: nlg-model-tf-1.py\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m Successfully installed nlg-model-tf-1.py-1.0.0\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m \u001b[33mWARNING: You are using pip version 20.1; however, version 20.2.3 is available.\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m You should consider upgrading via the '/usr/local/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m 2020-09-29 02:39:30,093 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m 2020-09-29 02:39:30,109 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m 2020-09-29 02:39:30,125 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m 2020-09-29 02:39:30,136 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m \n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m Training Env:\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m \n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m {\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m         \"pkl\": \"/opt/ml/input/data/pkl\"\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m     \"current_host\": \"algo-1-nfqu5\",\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m     \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m     \"hosts\": [\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m         \"algo-1-nfqu5\"\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m     ],\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m         \"epochs\": 1,\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m         \"batch-size\": 128,\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m         \"model_dir\": \"s3://sagemaker-us-east-1-972098824814/tensorflow-training-2020-09-29-02-38-31-912/model\"\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m         \"pkl\": {\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m         }\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m     \"job_name\": \"tensorflow-training-2020-09-29-02-38-31-912\",\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m     \"master_hostname\": \"algo-1-nfqu5\",\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-972098824814/tensorflow-training-2020-09-29-02-38-31-912/source/sourcedir.tar.gz\",\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m     \"module_name\": \"nlg_model_tf_1\",\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m     \"num_cpus\": 8,\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m         \"current_host\": \"algo-1-nfqu5\",\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m         \"hosts\": [\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m             \"algo-1-nfqu5\"\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m         ]\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m     \"user_entry_point\": \"nlg_model_tf_1.py\"\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m \n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m Environment variables:\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m \n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m SM_HOSTS=[\"algo-1-nfqu5\"]\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m SM_HPS={\"batch-size\":128,\"epochs\":1,\"model_dir\":\"s3://sagemaker-us-east-1-972098824814/tensorflow-training-2020-09-29-02-38-31-912/model\"}\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m SM_USER_ENTRY_POINT=nlg_model_tf_1.py\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-nfqu5\",\"hosts\":[\"algo-1-nfqu5\"]}\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m SM_INPUT_DATA_CONFIG={\"pkl\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m SM_CHANNELS=[\"pkl\"]\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m SM_CURRENT_HOST=algo-1-nfqu5\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m SM_MODULE_NAME=nlg_model_tf_1\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m SM_NUM_CPUS=8\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-972098824814/tensorflow-training-2020-09-29-02-38-31-912/source/sourcedir.tar.gz\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"pkl\":\"/opt/ml/input/data/pkl\"},\"current_host\":\"algo-1-nfqu5\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1-nfqu5\"],\"hyperparameters\":{\"batch-size\":128,\"epochs\":1,\"model_dir\":\"s3://sagemaker-us-east-1-972098824814/tensorflow-training-2020-09-29-02-38-31-912/model\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"pkl\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tensorflow-training-2020-09-29-02-38-31-912\",\"log_level\":20,\"master_hostname\":\"algo-1-nfqu5\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-972098824814/tensorflow-training-2020-09-29-02-38-31-912/source/sourcedir.tar.gz\",\"module_name\":\"nlg_model_tf_1\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-nfqu5\",\"hosts\":[\"algo-1-nfqu5\"]},\"user_entry_point\":\"nlg_model_tf_1.py\"}\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m SM_USER_ARGS=[\"--batch-size\",\"128\",\"--epochs\",\"1\",\"--model_dir\",\"s3://sagemaker-us-east-1-972098824814/tensorflow-training-2020-09-29-02-38-31-912/model\"]\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m SM_CHANNEL_PKL=/opt/ml/input/data/pkl\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m SM_HP_EPOCHS=1\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m SM_HP_BATCH-SIZE=128\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m SM_HP_MODEL_DIR=s3://sagemaker-us-east-1-972098824814/tensorflow-training-2020-09-29-02-38-31-912/model\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m PYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python37.zip:/usr/local/lib/python3.7:/usr/local/lib/python3.7/lib-dynload:/usr/local/lib/python3.7/site-packages\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m \n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m \n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m /usr/local/bin/python3.7 -m nlg_model_tf_1 --batch-size 128 --epochs 1 --model_dir s3://sagemaker-us-east-1-972098824814/tensorflow-training-2020-09-29-02-38-31-912/model\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m \n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m \n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m \n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m   File \"/usr/local/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m     \"__main__\", mod_spec)\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m   File \"/usr/local/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m     exec(code, run_globals)\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m   File \"/opt/ml/code/nlg_model_tf_1.py\", line 195, in <module>\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m     with open(desc_path, 'rb') as fp:\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m FileNotFoundError: [Errno 2] No such file or directory: '/opt/ml/input/data/pkl/condensed_descriptions.pkl'\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m 2020-09-29 02:39:31,912 sagemaker-training-toolkit ERROR    ExecuteUserScriptError:\n",
      "\u001b[36malgo-1-nfqu5_1  |\u001b[0m Command \"/usr/local/bin/python3.7 -m nlg_model_tf_1 --batch-size 128 --epochs 1 --model_dir s3://sagemaker-us-east-1-972098824814/tensorflow-training-2020-09-29-02-38-31-912/model\"\n",
      "\u001b[36mtmp9e2lguv4_algo-1-nfqu5_1 exited with code 1\n",
      "\u001b[0mAborting on container exit...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run: ['docker-compose', '-f', '/tmp/tmp9e2lguv4/docker-compose.yaml', 'up', '--build', '--abort-on-container-exit'], Process exited with code: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/local/image.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, job_name)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             \u001b[0m_stream_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/local/image.py\u001b[0m in \u001b[0;36m_stream_output\u001b[0;34m(process)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexit_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Process exited with code: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mexit_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Process exited with code: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d32cdfeaf896>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'pkl'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpkl_dir\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/tensorflow/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config, run_tensorboard_locally)\u001b[0m\n\u001b[1;32m    481\u001b[0m                 \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m             \u001b[0mfit_super\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/tensorflow/estimator.py\u001b[0m in \u001b[0;36mfit_super\u001b[0;34m()\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfit_super\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensorFlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_tensorboard_locally\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mwait\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_for_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TrainingJob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mstart_new\u001b[0;34m(cls, estimator, inputs, experiment_config)\u001b[0m\n\u001b[1;32m   1089\u001b[0m             \u001b[0mtrain_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"enable_sagemaker_metrics\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_sagemaker_metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_job_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_mode, input_config, role, job_name, output_config, resource_config, vpc_config, hyperparameters, stop_condition, tags, metric_definitions, enable_network_isolation, image, algorithm_arn, encrypt_inter_container_traffic, train_use_spot_instances, checkpoint_s3_uri, checkpoint_local_path, experiment_config, debugger_rule_configs, debugger_hook_config, tensorboard_output_config, enable_sagemaker_metrics)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating training-job with name: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train request: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_training_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     def process(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/local/local_session.py\u001b[0m in \u001b[0;36mcreate_training_job\u001b[0;34m(self, TrainingJobName, AlgorithmSpecification, OutputDataConfig, ResourceConfig, InputDataConfig, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mhyperparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"HyperParameters\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"HyperParameters\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training job\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtraining_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInputDataConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOutputDataConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingJobName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mLocalSagemakerClient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_training_jobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTrainingJobName\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/local/entities.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, job_name)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         self.model_artifacts = self.container.train(\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0minput_data_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_data_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         )\n\u001b[1;32m     97\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/local/image.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, job_name)\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0;31m# which contains the exit code and append the command line to it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Failed to run: %s, %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcompose_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0martifacts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve_artifacts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompose_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_data_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to run: ['docker-compose', '-f', '/tmp/tmp9e2lguv4/docker-compose.yaml', 'up', '--build', '--abort-on-container-exit'], Process exited with code: 1"
     ]
    }
   ],
   "source": [
    "tf_estimator.fit({'pkl': pkl_dir})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_estimator = TensorFlow(entry_point = 'SCRIPT/nlg_model_tf_1.py', \n",
    "                         role = role, \n",
    "                         train_instance_count = 1, \n",
    "                         train_instance_type = 'ml.p2.xlarge',\n",
    "                         py_version = 'py37', \n",
    "                         framework_version = '1.15.2',\n",
    "                         script_mode = True, \n",
    "                         hyperparameters = {'epochs': epochs, \n",
    "                                           'batch-size': batch_size}\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_estimator.fit({'pkl': pkl_dir})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "tf_endpoint = 'nlg-model-tf-'+time.strftime('%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "\n",
    "# GPU\n",
    "#tf_predictor = tf_estimator.deploy(initial_instance_count = 1, \n",
    "#                                   instance_type = 'ml.p2.xlarge')\n",
    "\n",
    "\n",
    "tf_predictor = tf_estimator.deploy(initial_instance_count = 1, \n",
    "                                  instance_type = 'ml.c5.large', \n",
    "                                  accelerator_type = 'ml.eia1.medium', \n",
    "                                  endpoint_name = tf_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SCRIPT.evaluation_tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# testing on photo data\n",
    "pred_list, score = get_bleu(test_list, \n",
    "                            features, \n",
    "                            tokenizer, \n",
    "                            max_length, \n",
    "                            tf_predictor, \n",
    "                            descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing on photo data\n",
    "artpred_list, artscore = get_bleu(test_list_art, \n",
    "                            features, \n",
    "                            tokenizer, \n",
    "                            max_length, \n",
    "                            tf_predictor, \n",
    "                            descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flicker_descriptor = descriptor(features, tokenizer, processor, model)\n",
    "#flicker_descriptor.test_random_image(img_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#art_descriptor = descriptor(features, tokenizer, processor, model,img_dir = art_dir)\n",
    "#art_descriptor.test_one_image(img_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete End-point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.delete_endpoint(endpoint_name = tf_endpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
