{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection - Harvard\n",
    "In this notebook, I'll collect data from Harvard Museum API.  \n",
    "Information can be found here: https://github.com/harvardartmuseums/api-docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "\n",
    "import pickle\n",
    "\n",
    "import time\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting keys from local drive\n",
    "def get_keys(path):\n",
    "    with open(path) as f: \n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = r\"path\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = get_keys(f\"{path}/harvard_mus_api.json\")[\"api_key\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "url = \"https://api.harvardartmuseums.org/classification\"\n",
    "\n",
    "url_params = {\n",
    "    \"apikey\": api_key,\n",
    "}\n",
    "\n",
    "resp = requests.get(url, params = url_params)\n",
    "print(resp.status_code)\n",
    "# good if 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking what type of classifications available from this API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifications = []\n",
    "\n",
    "n = int(resp.json()['info']['pages']) # getting the page number \n",
    "        \n",
    "for i in range(n):\n",
    "    url_params[\"page\"] = i\n",
    "    print(f\"page {i}\")\n",
    "    \n",
    "    resp = requests.get(url, params = url_params)\n",
    "\n",
    "    try: \n",
    "        classifications.extend(resp.json()['records']) # add it to the list\n",
    "    except:\n",
    "        print(f\"Error on page {i+1}\") # let me know if there's an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications = pd.DataFrame(classifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>objectcount</th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>lastupdate</th>\n",
       "      <th>classificationid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>84315</td>\n",
       "      <td>Photographs</td>\n",
       "      <td>17</td>\n",
       "      <td>2020-09-15T04:29:44-0400</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>27702</td>\n",
       "      <td>Drawings</td>\n",
       "      <td>21</td>\n",
       "      <td>2020-09-15T04:29:44-0400</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6978</td>\n",
       "      <td>Paintings</td>\n",
       "      <td>26</td>\n",
       "      <td>2020-09-15T04:29:44-0400</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6978</td>\n",
       "      <td>Paintings</td>\n",
       "      <td>26</td>\n",
       "      <td>2020-09-15T04:29:44-0400</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6244</td>\n",
       "      <td>Sculpture</td>\n",
       "      <td>30</td>\n",
       "      <td>2020-09-15T04:29:44-0400</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>6190</td>\n",
       "      <td>Vessels</td>\n",
       "      <td>57</td>\n",
       "      <td>2020-09-15T04:29:44-0400</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>5898</td>\n",
       "      <td>Seals</td>\n",
       "      <td>189</td>\n",
       "      <td>2020-09-15T04:29:44-0400</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4880</td>\n",
       "      <td>Straus Materials</td>\n",
       "      <td>959</td>\n",
       "      <td>2020-09-15T04:29:44-0400</td>\n",
       "      <td>959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4800</td>\n",
       "      <td>Fragments</td>\n",
       "      <td>94</td>\n",
       "      <td>2020-09-15T04:29:44-0400</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>4388</td>\n",
       "      <td>Manuscripts</td>\n",
       "      <td>185</td>\n",
       "      <td>2020-09-15T04:29:44-0400</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    objectcount              name   id                lastupdate  \\\n",
       "59        84315       Photographs   17  2020-09-15T04:29:44-0400   \n",
       "20        27702          Drawings   21  2020-09-15T04:29:44-0400   \n",
       "15         6978         Paintings   26  2020-09-15T04:29:44-0400   \n",
       "5          6978         Paintings   26  2020-09-15T04:29:44-0400   \n",
       "21         6244         Sculpture   30  2020-09-15T04:29:44-0400   \n",
       "35         6190           Vessels   57  2020-09-15T04:29:44-0400   \n",
       "49         5898             Seals  189  2020-09-15T04:29:44-0400   \n",
       "43         4880  Straus Materials  959  2020-09-15T04:29:44-0400   \n",
       "25         4800         Fragments   94  2020-09-15T04:29:44-0400   \n",
       "48         4388       Manuscripts  185  2020-09-15T04:29:44-0400   \n",
       "\n",
       "    classificationid  \n",
       "59                17  \n",
       "20                21  \n",
       "15                26  \n",
       "5                 26  \n",
       "21                30  \n",
       "35                57  \n",
       "49               189  \n",
       "43               959  \n",
       "25                94  \n",
       "48               185  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifications.sort_values(by = 'objectcount', ascending = False)[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting Full Data\n",
    "It seems like paintings alone could give us enough data for now. I'll collect all paintings data and download each images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://api.harvardartmuseums.org/object\"\n",
    "\n",
    "url_params = {\n",
    "    \"apikey\": api_key, \n",
    "    \"classification\": 'Paintings'\n",
    "}\n",
    "\n",
    "resp = requests.get(url, params = url_params)\n",
    "\n",
    "resp.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# getting the number of pages\n",
    "n = int(resp.json()['info']['pages'])\n",
    "full_db = []\n",
    "\n",
    "for i in range(219,n):\n",
    "    url_params['page'] = i\n",
    "    resp = requests.get(url, params = url_params)\n",
    "    try: \n",
    "        full_db.extend(resp.json()['records'])\n",
    "    except:\n",
    "        print(f\"error on page {i+1}\")\n",
    "              \n",
    "    pause = np.random.randint(1, 60)\n",
    "    print(f'{i+1}/{n} complete. pausing for {pause} secs ...')\n",
    "    time.sleep(pause) # buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(full_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving\n",
    "full_df = df.drop_duplicates(subset = 'id')\n",
    "filename = 'PKL/raw_data_Harvard.pkl'\n",
    "full_df.to_pickle(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "# full_df = pd.read_pickle('PKL/raw_data_Harvard.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading Images\n",
    "Now I'll take the url in the dataset and download them to the local drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id_set = full_df[['id', 'primaryimageurl']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading images\n",
    "def download_img(df): \n",
    "    url = str(df['primaryimageurl'])\n",
    "    print(f'connecting {url}...')\n",
    "    if url.startswith('http'):\n",
    "        resp = requests.get(url)\n",
    "        print(resp.status_code)\n",
    "        \n",
    "        # writing to a local drive\n",
    "        fpath = f\"IMAGES/HARVARD/{df['id']}.jpg\"\n",
    "        with open(fpath, 'wb') as fp:\n",
    "            fp.write(resp.content)\n",
    "\n",
    "        # open and resize it to smaller thumbnail\n",
    "        img = Image.open(fpath)\n",
    "        img.thumbnail((500, 500))\n",
    "        img.save(fpath)\n",
    "    else:\n",
    "        print('error')\n",
    "    \n",
    "    # give some buffer to distribute traffic\n",
    "    pause = np.random.randint(1, 60)\n",
    "    print(f'pausing for {pause} secs ...')\n",
    "    time.sleep(pause) # buffer\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run it\n",
    "image_id_set.apply(lambda x: download_img(x), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
